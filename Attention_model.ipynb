{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvtCb720266EyUIoi6qHaN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/BP_PPG/blob/master/Attention_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjDmZEgDNrKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceebec02-9190-4e19-dc89-c5558919e48e"
      },
      "source": [
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%load_ext tensorboard\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import wfdb\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import load_model \n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Input, Add, Activation,\\\n",
        "MaxPooling1D,Dropout,Flatten,TimeDistributed,Bidirectional,Dense,LSTM, ZeroPadding1D, \\\n",
        "AveragePooling1D,GlobalMaxPooling1D, Concatenate, Permute, Dot, Multiply, RepeatVector,\\\n",
        "Lambda\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import tensorflow_datasets as tfds\n",
        "import multiprocessing\n",
        "from datetime import datetime\n",
        "import sklearn.metrics\n",
        "import itertools\n",
        "import io\n",
        "import pickle\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYpoh25l2I-8",
        "colab_type": "text"
      },
      "source": [
        "##ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azITSoM_2FGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block_18(X, f, filters, stage, block):\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv1D(filters = F1, kernel_size = f, strides = 1, padding = 'same', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 2, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    # Second component of main path \n",
        "    X = Conv1D(filters = F2, kernel_size = f, strides = 1, padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 2, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation \n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmh6EkhM2HkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet18(input_shape=(750, 1), classes=1):\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding1D(3)(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv1D(64, 7, strides=2, name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=2, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling1D(3, strides=2)(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = identity_block_18(X, 3, [64, 64], stage=2, block='a')\n",
        "    X = identity_block_18(X, 3, [64, 64], stage=2, block='b')\n",
        "\n",
        "\n",
        "    # Stage 3 (2 lines)\n",
        "    X = convolutional_block_18(X, f = 3, filters = [128, 128], stage = 3, block='a', s = 2)\n",
        "    X = identity_block_18(X, 3, [128, 128], stage=3, block='b')\n",
        "\n",
        "\n",
        "    # Stage 4 (2 lines)\n",
        "    X = convolutional_block_18(X, f = 3, filters = [256, 256], stage = 4, block='a', s = 2)\n",
        "    X = identity_block_18(X, 3, [256, 256], stage=4, block='b')\n",
        "\n",
        "    # Stage 5 (2 lines)\n",
        "    X = convolutional_block_18(X, f = 3, filters = [512, 512], stage = 5, block='a', s = 2)\n",
        "    X = identity_block_18(X, 3, [512, 512], stage=5, block='b')\n",
        "\n",
        "\n",
        "    # AVGPOOL (1 line).\n",
        "    X = AveragePooling1D(2, name=\"avg_pool\")(X)\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "    \n",
        "    \n",
        "    #X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    #Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet18')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiJzvHsa2GbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block_18(X, f, filters, stage, block, s = 2):\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv1D(filters = F1, kernel_size = f, strides = s, padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 2, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv1D(filters = F2, kernel_size = f, strides = 1, padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 2, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv1D(filters = F1, kernel_size = f, strides = s, padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 2, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdHGkk4y2M50",
        "colab_type": "text"
      },
      "source": [
        "##Attention Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1CzBGm1ih-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_step_attention(a, s_prev): \n",
        "  \"\"\"\n",
        "  Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
        "  \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
        "  \n",
        "  Arguments:\n",
        "  a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
        "  s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
        "  \n",
        "  Returns:\n",
        "  context -- context vector, input of the next (post-attention) LSTM cell\n",
        "  \"\"\"\n",
        "  s_prev = RepeatVector(Tx)(s_prev)\n",
        "  concat = Concatenate(axis=-1)([a, s_prev])\n",
        "  e = Dense(10, activation = \"tanh\")(concat)\n",
        "  energies = Dense(1, activation = \"relu\")(e)\n",
        "  alphas = Activation(tf.nn.softmax(energies,axis=1), name = 'attention_weights')\n",
        "  context = Dot(axes = 1)([alphas,a])\n",
        "  \n",
        "  return context"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2moud0yog-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Attention(Tx, Ty, n_a, n_s, input_image_size, output_size):\n",
        "  \"\"\"\n",
        "  Arguments:\n",
        "  Tx -- length of the input sequence = 10\n",
        "  Ty -- length of the output sequence = 10, similar to one-to-one LSTMs\n",
        "  n_a -- hidden state size of the Bi-LSTM = 32\n",
        "  n_s -- hidden state size of the post-attention LSTM = 16\n",
        "  input_image_size -- size of the input image = 750\n",
        "  output_size -- size of output = 2, since there are two BP values\n",
        "\n",
        "  Returns:\n",
        "  model -- Keras model instance\n",
        "  \"\"\"\n",
        "  # Define the inputs of your model with a shape (Tx,)\n",
        "  # Define s0 and c0, initial hidden state for the decoder(post) LSTM of shape (n_s,)\n",
        "  X = Input(shape = (Tx, input_image_size))\n",
        "  s0 = Input(shape = (n_s, ), name = 's0')\n",
        "  c0 = Input(shape = (n_s, ), name = 'c0')\n",
        "  s = s0\n",
        "  c = c0\n",
        "\n",
        "  #Initialize empty list of outputs\n",
        "  outputs = []\n",
        "\n",
        "  a = Bidirectional(LSTM(n_a, return_sequences=True))(X)\n",
        "\n",
        "  for t in range(Ty):\n",
        "    context = one_step_attention(a, s)\n",
        "    s, _, c = LSTM(n_s, return_state = True)(context, initial_state = [s, c])\n",
        "    out = Dense(output_size)(s)\n",
        "    outputs.append(out)\n",
        "  \n",
        "  outputs = Dense(2)(outputs) \n",
        "  model = Model(inputs = [X, s0, c0], outputs = outputs)\n",
        "\n",
        "  return attention"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzJ9S6q92RAC",
        "colab_type": "text"
      },
      "source": [
        "##ResNet-18 + Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmSizTCmtSIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Tx=10 #Number of input images\n",
        "Ty=10 #Number of post-LSTM cells\n",
        "n_a=32 #Number of pre-LSTM states\n",
        "n_s=16 #Number of post-LSTM states\n",
        "input_image_size=750 #Input image size\n",
        "output_size=2 #output of each post-LSTM cells before applying the FINAL dense layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9G7swOO1qJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "42910abd-0073-4f5f-d6c3-df73d85997be"
      },
      "source": [
        "resnet = ResNet18(input_shape = (input_image_size,1), classes = 1)\n",
        "attention = Attention(Tx, Ty, n_a, n_s, input_image_size, output_size)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-24-2f38b411587d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mResNet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_image_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_image_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-20-5e6728a98596>\u001b[0m in \u001b[0;36mAttention\u001b[1;34m(Tx, Ty, n_a, n_s, input_image_size, output_size)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_step_attention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-23-459d10f838c0>\u001b[0m in \u001b[0;36mone_step_attention\u001b[1;34m(a, s_prev)\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"tanh\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m   \u001b[0menergies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m   \u001b[0malphas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menergies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'attention_weights'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m   \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0malphas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, activation, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_masking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    467\u001b[0m     raise TypeError(\n\u001b[0;32m    468\u001b[0m         'Could not interpret activation function identifier: {}'.format(\n\u001b[1;32m--> 469\u001b[1;33m             repr(identifier)))\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: Could not interpret activation function identifier: <tf.Tensor 'Transpose_1:0' shape=(None, 10, 1) dtype=float32>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6z3yGPrwGP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.TimeDistributed(resnet, input_shape = (Tx, input_image_size,1)),\n",
        "        attention\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}